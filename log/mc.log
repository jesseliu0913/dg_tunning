W1218 21:48:49.620000 3553748 site-packages/torch/distributed/run.py:793] 
W1218 21:48:49.620000 3553748 site-packages/torch/distributed/run.py:793] *****************************************
W1218 21:48:49.620000 3553748 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1218 21:48:49.620000 3553748 site-packages/torch/distributed/run.py:793] *****************************************
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.43s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.60s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.76s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.85s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.14s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.22s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.52s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.52s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.79s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.72s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.75s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  3.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.46s/it]
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:18<00:06,  6.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.66s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:18<00:06,  6.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.68s/it]
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:18<00:00,  4.70s/it]
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.93s/it]
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.99s/it]
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/playpen/xinyu/jesse/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: l-zijie. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /playpen/xinyu/jesse/dg_tunning/wandb/run-20241218_215012-szp7m3ft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ./qwen_mc_results
wandb: ⭐️ View project at https://wandb.ai/l-zijie/huggingface
wandb: 🚀 View run at https://wandb.ai/l-zijie/huggingface/runs/szp7m3ft
  0%|          | 0/475 [00:00<?, ?it/s]/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  0%|          | 1/475 [00:52<6:57:05, 52.80s/it]  0%|          | 2/475 [01:46<7:02:34, 53.60s/it]  1%|          | 3/475 [02:39<6:58:33, 53.21s/it]W1218 21:53:28.638000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3553822 closing signal SIGTERM
W1218 21:53:28.639000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3553824 closing signal SIGTERM
W1218 21:53:28.639000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3553825 closing signal SIGTERM
W1218 21:53:28.640000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3553826 closing signal SIGTERM
W1218 21:53:28.640000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3553827 closing signal SIGTERM
E1218 21:53:29.472000 3553748 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 1 (pid: 3553823) of binary: /home/xinyuzh/anaconda3/envs/meditron/bin/python
Traceback (most recent call last):
  File "/home/xinyuzh/anaconda3/envs/meditron/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
tune_umls.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-18_21:53:28
  host      : unites3.cs.unc.edu
  rank      : 1 (local_rank: 1)
  exitcode  : -9 (pid: 3553823)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3553823
========================================================
