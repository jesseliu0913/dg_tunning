W1215 17:34:35.294000 90028 site-packages/torch/distributed/run.py:793] 
W1215 17:34:35.294000 90028 site-packages/torch/distributed/run.py:793] *****************************************
W1215 17:34:35.294000 90028 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1215 17:34:35.294000 90028 site-packages/torch/distributed/run.py:793] *****************************************
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.59s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.63s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.62s/it]
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.74s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.75s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.79s/it]
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.83s/it]
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/mnt/dg_tunning/tune_umls.py:144: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: l-zijie. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.5
wandb: Run data is saved locally in /mnt/dg_tunning/wandb/run-20241215_173501-xn89q4yk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ./qwen_qa_results
wandb: ⭐️ View project at https://wandb.ai/l-zijie/huggingface
wandb: 🚀 View run at https://wandb.ai/l-zijie/huggingface/runs/xn89q4yk
  0%|          | 0/328 [00:00<?, ?it/s]  0%|          | 1/328 [00:12<1:07:55, 12.46s/it]  1%|          | 2/328 [00:24<1:05:44, 12.10s/it]  1%|          | 3/328 [00:36<1:04:55, 11.99s/it]  1%|          | 4/328 [00:48<1:04:31, 11.95s/it]  2%|▏         | 5/328 [00:59<1:04:10, 11.92s/it]  2%|▏         | 6/328 [01:11<1:03:57, 11.92s/it]  2%|▏         | 7/328 [01:23<1:03:46, 11.92s/it]  2%|▏         | 8/328 [01:35<1:03:35, 11.92s/it]  3%|▎         | 9/328 [01:47<1:03:23, 11.92s/it]  3%|▎         | 10/328 [01:59<1:03:11, 11.92s/it]  3%|▎         | 11/328 [02:11<1:03:00, 11.93s/it]  4%|▎         | 12/328 [02:23<1:02:49, 11.93s/it]  4%|▍         | 13/328 [02:35<1:02:38, 11.93s/it]  4%|▍         | 14/328 [02:47<1:02:27, 11.93s/it]  5%|▍         | 15/328 [02:59<1:02:13, 11.93s/it]  5%|▍         | 16/328 [03:11<1:02:04, 11.94s/it]  5%|▌         | 17/328 [03:23<1:01:49, 11.93s/it]  5%|▌         | 18/328 [03:35<1:01:39, 11.94s/it]  6%|▌         | 19/328 [03:46<1:01:26, 11.93s/it]  6%|▌         | 20/328 [03:58<1:01:17, 11.94s/it]  6%|▋         | 21/328 [04:10<1:01:05, 11.94s/it]  7%|▋         | 22/328 [04:22<1:00:53, 11.94s/it]  7%|▋         | 23/328 [04:34<1:00:42, 11.94s/it]  7%|▋         | 24/328 [04:46<1:00:30, 11.94s/it]  8%|▊         | 25/328 [04:58<1:00:18, 11.94s/it]  8%|▊         | 26/328 [05:10<1:00:05, 11.94s/it]  8%|▊         | 27/328 [05:22<59:54, 11.94s/it]    9%|▊         | 28/328 [05:34<59:43, 11.95s/it]  9%|▉         | 29/328 [05:46<59:30, 11.94s/it]  9%|▉         | 30/328 [05:58<59:20, 11.95s/it]  9%|▉         | 31/328 [06:10<59:07, 11.94s/it] 10%|▉         | 32/328 [06:22<58:55, 11.94s/it] 10%|█         | 33/328 [06:34<58:53, 11.98s/it] 10%|█         | 34/328 [06:46<58:37, 11.96s/it] 11%|█         | 35/328 [06:58<58:47, 12.04s/it] 11%|█         | 36/328 [07:10<58:26, 12.01s/it] 11%|█▏        | 37/328 [07:22<58:07, 11.99s/it] 12%|█▏        | 38/328 [07:34<57:51, 11.97s/it] 12%|█▏        | 39/328 [07:46<57:35, 11.96s/it] 12%|█▏        | 40/328 [07:58<57:21, 11.95s/it] 12%|█▎        | 41/328 [08:09<57:07, 11.94s/it] 13%|█▎        | 42/328 [08:21<56:53, 11.94s/it] 13%|█▎        | 43/328 [08:33<56:41, 11.94s/it] 13%|█▎        | 44/328 [08:45<56:29, 11.93s/it] 14%|█▎        | 45/328 [08:57<56:17, 11.93s/it] 14%|█▍        | 46/328 [09:09<56:04, 11.93s/it] 14%|█▍        | 47/328 [09:21<55:52, 11.93s/it] 15%|█▍        | 48/328 [09:33<55:38, 11.92s/it] 15%|█▍        | 49/328 [09:45<55:27, 11.93s/it] 15%|█▌        | 50/328 [09:57<55:13, 11.92s/it] 16%|█▌        | 51/328 [10:09<55:02, 11.92s/it] 16%|█▌        | 52/328 [10:21<54:50, 11.92s/it] 16%|█▌        | 53/328 [10:33<54:40, 11.93s/it] 16%|█▋        | 54/328 [10:45<54:27, 11.93s/it] 17%|█▋        | 55/328 [10:56<54:14, 11.92s/it] 17%|█▋        | 56/328 [11:08<54:05, 11.93s/it] 17%|█▋        | 57/328 [11:20<53:52, 11.93s/it] 18%|█▊        | 58/328 [11:32<53:41, 11.93s/it] 18%|█▊        | 59/328 [11:44<53:30, 11.93s/it] 18%|█▊        | 60/328 [11:56<53:18, 11.94s/it] 19%|█▊        | 61/328 [12:08<53:06, 11.94s/it] 19%|█▉        | 62/328 [12:20<52:53, 11.93s/it] 19%|█▉        | 63/328 [12:32<52:40, 11.93s/it] 20%|█▉        | 64/328 [12:44<52:28, 11.93s/it] 20%|█▉        | 65/328 [12:56<52:15, 11.92s/it] 20%|██        | 66/328 [13:08<52:05, 11.93s/it] 20%|██        | 67/328 [13:20<51:53, 11.93s/it] 21%|██        | 68/328 [13:32<51:40, 11.93s/it] 21%|██        | 69/328 [13:43<51:29, 11.93s/it] 21%|██▏       | 70/328 [13:55<51:17, 11.93s/it] 22%|██▏       | 71/328 [14:07<51:04, 11.93s/it] 22%|██▏       | 72/328 [14:19<50:53, 11.93s/it] 22%|██▏       | 73/328 [14:31<50:39, 11.92s/it] 23%|██▎       | 74/328 [14:43<50:36, 11.95s/it] 23%|██▎       | 75/328 [14:55<50:22, 11.95s/it] 23%|██▎       | 76/328 [15:07<50:23, 12.00s/it] 23%|██▎       | 77/328 [15:19<50:06, 11.98s/it] 24%|██▍       | 78/328 [15:31<49:51, 11.97s/it] 24%|██▍       | 79/328 [15:43<49:36, 11.95s/it] 24%|██▍       | 80/328 [15:55<49:20, 11.94s/it] 25%|██▍       | 81/328 [16:07<49:08, 11.94s/it] 25%|██▌       | 82/328 [16:19<48:55, 11.93s/it] 25%|██▌       | 83/328 [16:31<48:43, 11.93s/it] 26%|██▌       | 84/328 [16:43<48:31, 11.93s/it] 26%|██▌       | 85/328 [16:55<48:20, 11.94s/it] 26%|██▌       | 86/328 [17:07<48:07, 11.93s/it] 27%|██▋       | 87/328 [17:18<47:55, 11.93s/it] 27%|██▋       | 88/328 [17:30<47:44, 11.93s/it] 27%|██▋       | 89/328 [17:42<47:32, 11.93s/it] 27%|██▋       | 90/328 [17:54<47:20, 11.93s/it] 28%|██▊       | 91/328 [18:06<47:07, 11.93s/it] 28%|██▊       | 92/328 [18:18<46:54, 11.93s/it] 28%|██▊       | 93/328 [18:30<46:43, 11.93s/it] 29%|██▊       | 94/328 [18:42<46:32, 11.93s/it] 29%|██▉       | 95/328 [18:54<46:20, 11.93s/it] 29%|██▉       | 96/328 [19:06<46:08, 11.93s/it] 30%|██▉       | 97/328 [19:18<45:58, 11.94s/it] 30%|██▉       | 98/328 [19:30<45:46, 11.94s/it] 30%|███       | 99/328 [19:42<45:34, 11.94s/it] 30%|███       | 100/328 [19:54<45:22, 11.94s/it]                                                 {'loss': 21.1773, 'grad_norm': 22.747098922729492, 'learning_rate': 1.7560664820493502e-05, 'epoch': 0.61}
 30%|███       | 100/328 [19:54<45:22, 11.94s/it] 31%|███       | 101/328 [20:06<45:10, 11.94s/it] 31%|███       | 102/328 [20:17<44:57, 11.94s/it] 31%|███▏      | 103/328 [20:29<44:45, 11.94s/it] 32%|███▏      | 104/328 [20:41<44:34, 11.94s/it] 32%|███▏      | 105/328 [20:53<44:23, 11.94s/it] 32%|███▏      | 106/328 [21:05<44:11, 11.94s/it] 33%|███▎      | 107/328 [21:17<43:59, 11.94s/it] 33%|███▎      | 108/328 [21:29<43:47, 11.94s/it] 33%|███▎      | 109/328 [21:41<43:35, 11.94s/it] 34%|███▎      | 110/328 [21:53<43:23, 11.94s/it] 34%|███▍      | 111/328 [22:05<43:12, 11.95s/it] 34%|███▍      | 112/328 [22:17<43:01, 11.95s/it] 34%|███▍      | 113/328 [22:29<42:48, 11.95s/it] 35%|███▍      | 114/328 [22:41<42:36, 11.94s/it] 35%|███▌      | 115/328 [22:53<42:24, 11.95s/it] 35%|███▌      | 116/328 [23:05<42:19, 11.98s/it] 36%|███▌      | 117/328 [23:17<42:05, 11.97s/it] 36%|███▌      | 118/328 [23:29<42:03, 12.02s/it] 36%|███▋      | 119/328 [23:41<41:47, 12.00s/it] 37%|███▋      | 120/328 [23:53<41:32, 11.98s/it] 37%|███▋      | 121/328 [24:05<41:17, 11.97s/it] 37%|███▋      | 122/328 [24:17<41:03, 11.96s/it] 38%|███▊      | 123/328 [24:29<40:51, 11.96s/it] 38%|███▊      | 124/328 [24:41<40:38, 11.95s/it] 38%|███▊      | 125/328 [24:53<40:26, 11.95s/it] 38%|███▊      | 126/328 [25:04<40:14, 11.95s/it] 39%|███▊      | 127/328 [25:16<40:02, 11.95s/it] 39%|███▉      | 128/328 [25:28<39:49, 11.95s/it] 39%|███▉      | 129/328 [25:40<39:37, 11.95s/it] 40%|███▉      | 130/328 [25:52<39:26, 11.95s/it] 40%|███▉      | 131/328 [26:04<39:14, 11.95s/it] 40%|████      | 132/328 [26:16<39:02, 11.95s/it] 41%|████      | 133/328 [26:28<38:49, 11.95s/it] 41%|████      | 134/328 [26:40<38:38, 11.95s/it] 41%|████      | 135/328 [26:52<38:25, 11.95s/it] 41%|████▏     | 136/328 [27:04<38:12, 11.94s/it] 42%|████▏     | 137/328 [27:16<38:00, 11.94s/it] 42%|████▏     | 138/328 [27:28<37:49, 11.94s/it] 42%|████▏     | 139/328 [27:40<37:36, 11.94s/it] 43%|████▎     | 140/328 [27:52<37:24, 11.94s/it] 43%|████▎     | 141/328 [28:04<37:12, 11.94s/it] 43%|████▎     | 142/328 [28:16<37:00, 11.94s/it] 44%|████▎     | 143/328 [28:28<36:48, 11.94s/it] 44%|████▍     | 144/328 [28:39<36:38, 11.95s/it] 44%|████▍     | 145/328 [28:51<36:25, 11.95s/it] 45%|████▍     | 146/328 [29:03<36:14, 11.95s/it] 45%|████▍     | 147/328 [29:15<36:01, 11.94s/it] 45%|████▌     | 148/328 [29:27<35:49, 11.94s/it] 45%|████▌     | 149/328 [29:39<35:37, 11.94s/it] 46%|████▌     | 150/328 [29:51<35:25, 11.94s/it] 46%|████▌     | 151/328 [30:03<35:14, 11.95s/it] 46%|████▋     | 152/328 [30:15<35:02, 11.94s/it] 47%|████▋     | 153/328 [30:27<34:49, 11.94s/it] 47%|████▋     | 154/328 [30:39<34:37, 11.94s/it] 47%|████▋     | 155/328 [30:51<34:24, 11.94s/it] 48%|████▊     | 156/328 [31:03<34:12, 11.93s/it] 48%|████▊     | 157/328 [31:15<34:00, 11.93s/it] 48%|████▊     | 158/328 [31:27<33:57, 11.98s/it] 48%|████▊     | 159/328 [31:39<33:42, 11.97s/it] 49%|████▉     | 160/328 [31:51<33:37, 12.01s/it] 49%|████▉     | 161/328 [32:03<33:21, 11.98s/it] 49%|████▉     | 162/328 [32:15<33:06, 11.96s/it] 50%|████▉     | 163/328 [32:27<32:52, 11.95s/it] 50%|█████     | 164/328 [32:39<32:39, 11.95s/it]
  0%|          | 0/37 [00:00<?, ?it/s][A
  5%|▌         | 2/37 [00:02<00:41,  1.18s/it][A
  8%|▊         | 3/37 [00:04<00:56,  1.67s/it][A
 11%|█         | 4/37 [00:07<01:03,  1.93s/it][A
 14%|█▎        | 5/37 [00:09<01:06,  2.08s/it][A
 16%|█▌        | 6/37 [00:11<01:07,  2.17s/it][A
 19%|█▉        | 7/37 [00:14<01:06,  2.23s/it][A
 22%|██▏       | 8/37 [00:16<01:05,  2.27s/it][A
 24%|██▍       | 9/37 [00:18<01:04,  2.30s/it][A
 27%|██▋       | 10/37 [00:21<01:02,  2.32s/it][A
 30%|██▉       | 11/37 [00:23<01:00,  2.33s/it][A
 32%|███▏      | 12/37 [00:25<00:58,  2.34s/it][A
 35%|███▌      | 13/37 [00:28<00:56,  2.35s/it][A
 38%|███▊      | 14/37 [00:30<00:54,  2.35s/it][A
 41%|████      | 15/37 [00:33<00:51,  2.35s/it][A
 43%|████▎     | 16/37 [00:35<00:49,  2.36s/it][A
 46%|████▌     | 17/37 [00:37<00:47,  2.36s/it][A
 49%|████▊     | 18/37 [00:40<00:44,  2.36s/it][A
 51%|█████▏    | 19/37 [00:42<00:42,  2.36s/it][A
 54%|█████▍    | 20/37 [00:44<00:40,  2.36s/it][A
 57%|█████▋    | 21/37 [00:47<00:37,  2.36s/it][A
 59%|█████▉    | 22/37 [00:49<00:35,  2.36s/it][A
 62%|██████▏   | 23/37 [00:51<00:33,  2.36s/it][A
 65%|██████▍   | 24/37 [00:54<00:30,  2.36s/it][A
 68%|██████▊   | 25/37 [00:56<00:28,  2.36s/it][A
 70%|███████   | 26/37 [00:59<00:25,  2.36s/it][A
 73%|███████▎  | 27/37 [01:01<00:23,  2.36s/it][A
 76%|███████▌  | 28/37 [01:03<00:21,  2.37s/it][A
 78%|███████▊  | 29/37 [01:06<00:18,  2.37s/it][A
 81%|████████  | 30/37 [01:08<00:16,  2.37s/it][A
 84%|████████▍ | 31/37 [01:10<00:14,  2.36s/it][A
 86%|████████▋ | 32/37 [01:13<00:11,  2.36s/it][A
 89%|████████▉ | 33/37 [01:15<00:09,  2.36s/it][A
 92%|█████████▏| 34/37 [01:17<00:07,  2.36s/it][A
 95%|█████████▍| 35/37 [01:20<00:04,  2.36s/it][A
 97%|█████████▋| 36/37 [01:22<00:02,  2.36s/it][A
100%|██████████| 37/37 [01:25<00:00,  2.36s/it][A                                                 
                                               [A{'eval_loss': 3.893171548843384, 'eval_runtime': 87.4971, 'eval_samples_per_second': 11.635, 'eval_steps_per_second': 0.423, 'epoch': 1.0}
 50%|█████     | 164/328 [34:06<32:39, 11.95s/it]
100%|██████████| 37/37 [01:25<00:00,  2.36s/it][A
                                               [A/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
 50%|█████     | 165/328 [34:49<2:09:26, 47.65s/it] 51%|█████     | 166/328 [35:01<1:39:40, 36.92s/it] 51%|█████     | 167/328 [35:13<1:18:55, 29.42s/it] 51%|█████     | 168/328 [35:25<1:04:25, 24.16s/it] 52%|█████▏    | 169/328 [35:37<54:16, 20.48s/it]   52%|█████▏    | 170/328 [35:49<47:10, 17.91s/it] 52%|█████▏    | 171/328 [36:01<42:10, 16.12s/it] 52%|█████▏    | 172/328 [36:13<38:39, 14.87s/it] 53%|█████▎    | 173/328 [36:25<36:08, 13.99s/it] 53%|█████▎    | 174/328 [36:37<34:19, 13.37s/it] 53%|█████▎    | 175/328 [36:49<33:00, 12.94s/it] 54%|█████▎    | 176/328 [37:01<32:01, 12.64s/it] 54%|█████▍    | 177/328 [37:13<31:17, 12.43s/it] 54%|█████▍    | 178/328 [37:24<30:42, 12.28s/it] 55%|█████▍    | 179/328 [37:36<30:14, 12.18s/it] 55%|█████▍    | 180/328 [37:48<29:50, 12.10s/it] 55%|█████▌    | 181/328 [38:00<29:31, 12.05s/it] 55%|█████▌    | 182/328 [38:12<29:14, 12.02s/it] 56%|█████▌    | 183/328 [38:24<28:59, 11.99s/it] 56%|█████▌    | 184/328 [38:36<28:49, 12.01s/it] 56%|█████▋    | 185/328 [38:48<28:34, 11.99s/it] 57%|█████▋    | 186/328 [39:00<28:19, 11.97s/it] 57%|█████▋    | 187/328 [39:12<28:05, 11.96s/it] 57%|█████▋    | 188/328 [39:24<27:53, 11.95s/it] 58%|█████▊    | 189/328 [39:36<27:41, 11.95s/it] 58%|█████▊    | 190/328 [39:48<27:28, 11.94s/it] 58%|█████▊    | 191/328 [40:00<27:15, 11.94s/it] 59%|█████▊    | 192/328 [40:12<27:03, 11.94s/it] 59%|█████▉    | 193/328 [40:24<26:51, 11.93s/it] 59%|█████▉    | 194/328 [40:36<26:38, 11.93s/it] 59%|█████▉    | 195/328 [40:47<26:26, 11.93s/it] 60%|█████▉    | 196/328 [40:59<26:15, 11.93s/it] 60%|██████    | 197/328 [41:11<26:02, 11.92s/it] 60%|██████    | 198/328 [41:23<25:57, 11.98s/it] 61%|██████    | 199/328 [41:35<25:44, 11.98s/it] 61%|██████    | 200/328 [41:47<25:37, 12.01s/it]                                                 {'loss': 7.1802, 'grad_norm': 12.11580753326416, 'learning_rate': 7.938247608013021e-06, 'epoch': 1.22}
 61%|██████    | 200/328 [41:47<25:37, 12.01s/it] 61%|██████▏   | 201/328 [41:59<25:22, 11.99s/it] 62%|██████▏   | 202/328 [42:11<25:07, 11.97s/it] 62%|██████▏   | 203/328 [42:23<24:55, 11.96s/it] 62%|██████▏   | 204/328 [42:35<24:42, 11.95s/it] 62%|██████▎   | 205/328 [42:47<24:29, 11.95s/it] 63%|██████▎   | 206/328 [42:59<24:17, 11.95s/it] 63%|██████▎   | 207/328 [43:11<24:05, 11.95s/it] 63%|██████▎   | 208/328 [43:23<23:53, 11.95s/it] 64%|██████▎   | 209/328 [43:35<23:42, 11.95s/it] 64%|██████▍   | 210/328 [43:47<23:29, 11.95s/it] 64%|██████▍   | 211/328 [43:59<23:16, 11.94s/it] 65%|██████▍   | 212/328 [44:11<23:05, 11.94s/it] 65%|██████▍   | 213/328 [44:23<22:53, 11.94s/it] 65%|██████▌   | 214/328 [44:35<22:40, 11.94s/it] 66%|██████▌   | 215/328 [44:47<22:29, 11.94s/it] 66%|██████▌   | 216/328 [44:59<22:18, 11.95s/it] 66%|██████▌   | 217/328 [45:10<22:06, 11.95s/it] 66%|██████▋   | 218/328 [45:22<21:53, 11.94s/it] 67%|██████▋   | 219/328 [45:34<21:41, 11.94s/it] 67%|██████▋   | 220/328 [45:46<21:29, 11.94s/it] 67%|██████▋   | 221/328 [45:58<21:17, 11.94s/it] 68%|██████▊   | 222/328 [46:10<21:05, 11.94s/it] 68%|██████▊   | 223/328 [46:22<20:54, 11.94s/it] 68%|██████▊   | 224/328 [46:34<20:42, 11.94s/it] 69%|██████▊   | 225/328 [46:46<20:30, 11.94s/it] 69%|██████▉   | 226/328 [46:58<20:17, 11.94s/it] 69%|██████▉   | 227/328 [47:10<20:05, 11.93s/it] 70%|██████▉   | 228/328 [47:22<19:53, 11.93s/it] 70%|██████▉   | 229/328 [47:34<19:41, 11.94s/it] 70%|███████   | 230/328 [47:46<19:29, 11.94s/it] 70%|███████   | 231/328 [47:58<19:18, 11.94s/it] 71%|███████   | 232/328 [48:10<19:06, 11.94s/it] 71%|███████   | 233/328 [48:21<18:53, 11.93s/it] 71%|███████▏  | 234/328 [48:33<18:42, 11.94s/it] 72%|███████▏  | 235/328 [48:45<18:30, 11.94s/it] 72%|███████▏  | 236/328 [48:57<18:18, 11.94s/it] 72%|███████▏  | 237/328 [49:09<18:06, 11.94s/it] 73%|███████▎  | 238/328 [49:21<17:54, 11.94s/it] 73%|███████▎  | 239/328 [49:33<17:42, 11.93s/it] 73%|███████▎  | 240/328 [49:45<17:34, 11.98s/it] 73%|███████▎  | 241/328 [49:57<17:26, 12.03s/it] 74%|███████▍  | 242/328 [50:09<17:11, 12.00s/it] 74%|███████▍  | 243/328 [50:21<16:58, 11.98s/it] 74%|███████▍  | 244/328 [50:33<16:45, 11.97s/it] 75%|███████▍  | 245/328 [50:45<16:33, 11.97s/it] 75%|███████▌  | 246/328 [50:57<16:20, 11.96s/it] 75%|███████▌  | 247/328 [51:09<16:07, 11.95s/it] 76%|███████▌  | 248/328 [51:21<15:56, 11.95s/it] 76%|███████▌  | 249/328 [51:33<15:43, 11.95s/it] 76%|███████▌  | 250/328 [51:45<15:31, 11.95s/it] 77%|███████▋  | 251/328 [51:57<15:19, 11.94s/it] 77%|███████▋  | 252/328 [52:09<15:07, 11.94s/it] 77%|███████▋  | 253/328 [52:21<14:55, 11.94s/it] 77%|███████▋  | 254/328 [52:33<14:43, 11.93s/it] 78%|███████▊  | 255/328 [52:44<14:31, 11.94s/it] 78%|███████▊  | 256/328 [52:56<14:19, 11.93s/it] 78%|███████▊  | 257/328 [53:08<14:07, 11.93s/it] 79%|███████▊  | 258/328 [53:20<13:55, 11.94s/it] 79%|███████▉  | 259/328 [53:32<13:43, 11.94s/it] 79%|███████▉  | 260/328 [53:44<13:31, 11.94s/it] 80%|███████▉  | 261/328 [53:56<13:19, 11.94s/it] 80%|███████▉  | 262/328 [54:08<13:07, 11.93s/it] 80%|████████  | 263/328 [54:20<12:55, 11.93s/it] 80%|████████  | 264/328 [54:32<12:43, 11.93s/it] 81%|████████  | 265/328 [54:44<12:31, 11.93s/it] 81%|████████  | 266/328 [54:56<12:19, 11.93s/it] 81%|████████▏ | 267/328 [55:08<12:07, 11.93s/it] 82%|████████▏ | 268/328 [55:20<11:55, 11.93s/it] 82%|████████▏ | 269/328 [55:32<11:43, 11.93s/it] 82%|████████▏ | 270/328 [55:43<11:32, 11.93s/it] 83%|████████▎ | 271/328 [55:55<11:20, 11.94s/it] 83%|████████▎ | 272/328 [56:07<11:08, 11.94s/it] 83%|████████▎ | 273/328 [56:19<10:56, 11.93s/it] 84%|████████▎ | 274/328 [56:31<10:44, 11.93s/it] 84%|████████▍ | 275/328 [56:43<10:31, 11.92s/it] 84%|████████▍ | 276/328 [56:55<10:20, 11.93s/it] 84%|████████▍ | 277/328 [57:07<10:08, 11.93s/it] 85%|████████▍ | 278/328 [57:19<09:56, 11.93s/it] 85%|████████▌ | 279/328 [57:31<09:44, 11.93s/it] 85%|████████▌ | 280/328 [57:43<09:33, 11.94s/it] 86%|████████▌ | 281/328 [57:55<09:20, 11.93s/it] 86%|████████▌ | 282/328 [58:07<09:10, 11.98s/it] 86%|████████▋ | 283/328 [58:19<09:00, 12.02s/it] 87%|████████▋ | 284/328 [58:31<08:47, 11.99s/it] 87%|████████▋ | 285/328 [58:43<08:34, 11.97s/it] 87%|████████▋ | 286/328 [58:55<08:22, 11.96s/it] 88%|████████▊ | 287/328 [59:07<08:09, 11.95s/it] 88%|████████▊ | 288/328 [59:19<07:57, 11.95s/it] 88%|████████▊ | 289/328 [59:30<07:45, 11.94s/it] 88%|████████▊ | 290/328 [59:42<07:33, 11.95s/it] 89%|████████▊ | 291/328 [59:54<07:21, 11.94s/it] 89%|████████▉ | 292/328 [1:00:06<07:09, 11.94s/it] 89%|████████▉ | 293/328 [1:00:18<06:57, 11.94s/it] 90%|████████▉ | 294/328 [1:00:30<06:45, 11.94s/it] 90%|████████▉ | 295/328 [1:00:42<06:34, 11.94s/it] 90%|█████████ | 296/328 [1:00:54<06:22, 11.94s/it] 91%|█████████ | 297/328 [1:01:06<06:10, 11.94s/it] 91%|█████████ | 298/328 [1:01:18<05:58, 11.94s/it] 91%|█████████ | 299/328 [1:01:30<05:46, 11.93s/it] 91%|█████████▏| 300/328 [1:01:42<05:34, 11.94s/it]                                                   {'loss': 0.0953, 'grad_norm': 1.5365046262741089, 'learning_rate': 4.412873476110702e-07, 'epoch': 1.83}
 91%|█████████▏| 300/328 [1:01:42<05:34, 11.94s/it] 92%|█████████▏| 301/328 [1:01:54<05:22, 11.94s/it] 92%|█████████▏| 302/328 [1:02:06<05:10, 11.94s/it] 92%|█████████▏| 303/328 [1:02:18<04:58, 11.94s/it] 93%|█████████▎| 304/328 [1:02:30<04:46, 11.94s/it] 93%|█████████▎| 305/328 [1:02:42<04:34, 11.94s/it] 93%|█████████▎| 306/328 [1:02:53<04:22, 11.94s/it] 94%|█████████▎| 307/328 [1:03:05<04:10, 11.94s/it] 94%|█████████▍| 308/328 [1:03:17<03:58, 11.94s/it] 94%|█████████▍| 309/328 [1:03:29<03:46, 11.94s/it] 95%|█████████▍| 310/328 [1:03:41<03:34, 11.94s/it] 95%|█████████▍| 311/328 [1:03:53<03:22, 11.93s/it] 95%|█████████▌| 312/328 [1:04:05<03:10, 11.93s/it] 95%|█████████▌| 313/328 [1:04:17<02:58, 11.93s/it] 96%|█████████▌| 314/328 [1:04:29<02:47, 11.93s/it] 96%|█████████▌| 315/328 [1:04:41<02:35, 11.93s/it] 96%|█████████▋| 316/328 [1:04:53<02:23, 11.94s/it] 97%|█████████▋| 317/328 [1:05:05<02:11, 11.94s/it] 97%|█████████▋| 318/328 [1:05:17<01:59, 11.94s/it] 97%|█████████▋| 319/328 [1:05:29<01:47, 11.94s/it] 98%|█████████▊| 320/328 [1:05:41<01:35, 11.93s/it] 98%|█████████▊| 321/328 [1:05:52<01:23, 11.93s/it] 98%|█████████▊| 322/328 [1:06:04<01:11, 11.93s/it] 98%|█████████▊| 323/328 [1:06:16<00:59, 11.93s/it] 99%|█████████▉| 324/328 [1:06:28<00:47, 11.98s/it] 99%|█████████▉| 325/328 [1:06:41<00:36, 12.02s/it] 99%|█████████▉| 326/328 [1:06:52<00:23, 11.99s/it]100%|█████████▉| 327/328 [1:07:04<00:11, 11.97s/it]100%|██████████| 328/328 [1:07:16<00:00, 11.96s/it]/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(

  0%|          | 0/37 [00:00<?, ?it/s][A
  5%|▌         | 2/37 [00:02<00:40,  1.16s/it][A
  8%|▊         | 3/37 [00:04<00:56,  1.65s/it][A
 11%|█         | 4/37 [00:06<01:02,  1.91s/it][A
 14%|█▎        | 5/37 [00:09<01:05,  2.06s/it][A
 16%|█▌        | 6/37 [00:11<01:06,  2.15s/it][A
 19%|█▉        | 7/37 [00:14<01:06,  2.22s/it][A
 22%|██▏       | 8/37 [00:16<01:05,  2.26s/it][A
 24%|██▍       | 9/37 [00:18<01:04,  2.30s/it][A
 27%|██▋       | 10/37 [00:21<01:02,  2.32s/it][A
 30%|██▉       | 11/37 [00:23<01:00,  2.33s/it][A
 32%|███▏      | 12/37 [00:25<00:58,  2.34s/it][A
 35%|███▌      | 13/37 [00:28<00:56,  2.34s/it][A
 38%|███▊      | 14/37 [00:30<00:54,  2.35s/it][A
 41%|████      | 15/37 [00:32<00:51,  2.35s/it][A
 43%|████▎     | 16/37 [00:35<00:49,  2.36s/it][A
 46%|████▌     | 17/37 [00:37<00:47,  2.36s/it][A
 49%|████▊     | 18/37 [00:40<00:44,  2.36s/it][A
 51%|█████▏    | 19/37 [00:42<00:42,  2.36s/it][A
 54%|█████▍    | 20/37 [00:44<00:40,  2.36s/it][A
 57%|█████▋    | 21/37 [00:47<00:37,  2.36s/it][A
 59%|█████▉    | 22/37 [00:49<00:35,  2.36s/it][A
 62%|██████▏   | 23/37 [00:51<00:33,  2.36s/it][A
 65%|██████▍   | 24/37 [00:54<00:30,  2.36s/it][A
 68%|██████▊   | 25/37 [00:56<00:28,  2.36s/it][A
 70%|███████   | 26/37 [00:58<00:25,  2.36s/it][A
 73%|███████▎  | 27/37 [01:01<00:23,  2.36s/it][A
 76%|███████▌  | 28/37 [01:03<00:21,  2.36s/it][A
 78%|███████▊  | 29/37 [01:05<00:18,  2.36s/it][A
 81%|████████  | 30/37 [01:08<00:16,  2.36s/it][A
 84%|████████▍ | 31/37 [01:10<00:14,  2.36s/it][A
 86%|████████▋ | 32/37 [01:13<00:11,  2.36s/it][A
 89%|████████▉ | 33/37 [01:15<00:09,  2.36s/it][A
 92%|█████████▏| 34/37 [01:17<00:07,  2.36s/it][A
 95%|█████████▍| 35/37 [01:20<00:04,  2.36s/it][A
 97%|█████████▋| 36/37 [01:22<00:02,  2.36s/it][A
100%|██████████| 37/37 [01:24<00:00,  2.36s/it][A                                                   
                                               [A{'eval_loss': 0.014889119192957878, 'eval_runtime': 87.3293, 'eval_samples_per_second': 11.657, 'eval_steps_per_second': 0.424, 'epoch': 2.0}
100%|██████████| 328/328 [1:09:15<00:00, 11.96s/it]
100%|██████████| 37/37 [01:25<00:00,  2.36s/it][A
                                               [A/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
                                                   {'train_runtime': 4185.7815, 'train_samples_per_second': 4.377, 'train_steps_per_second': 0.078, 'train_loss': 8.676869797270472, 'epoch': 2.0}
100%|██████████| 328/328 [1:09:43<00:00, 11.96s/it]100%|██████████| 328/328 [1:09:43<00:00, 12.76s/it]
/root/miniconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
[1;34mwandb[0m: 🚀 View run [33m./qwen_qa_results[0m at: [34mhttps://wandb.ai/l-zijie/huggingface/runs/xn89q4yk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20241215_173501-xn89q4yk/logs[0m
