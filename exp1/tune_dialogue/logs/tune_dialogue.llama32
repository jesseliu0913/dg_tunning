W1230 23:50:33.567000 1742636 site-packages/torch/distributed/run.py:793] 
W1230 23:50:33.567000 1742636 site-packages/torch/distributed/run.py:793] *****************************************
W1230 23:50:33.567000 1742636 site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1230 23:50:33.567000 1742636 site-packages/torch/distributed/run.py:793] *****************************************
current model is: meta-llama/Llama-3.2-3B-Instruct
current model is: meta-llama/Llama-3.2-3B-Instruct
current model is: meta-llama/Llama-3.2-3B-Instruct
current model is: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.61s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:06<00:06,  6.88s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.58s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.63s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.64s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.09s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.50s/it]
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/playpen/xinyu/Jesse/dg_tunning/exp1/tune_dialogue/tune_umls_dialogue.py:202: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/playpen/xinyu/Jesse/dg_tunning/exp1/tune_dialogue/tune_umls_dialogue.py:202: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
/playpen/xinyu/Jesse/dg_tunning/exp1/tune_dialogue/tune_umls_dialogue.py:202: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
/playpen/xinyu/Jesse/dg_tunning/exp1/tune_dialogue/tune_umls_dialogue.py:202: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
wandb: Currently logged in as: l-zijie. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.1
wandb: Run data is saved locally in /playpen/xinyu/Jesse/dg_tunning/exp1/tune_dialogue/wandb/run-20241230_235352-rb2dcy5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ./qwen_dialogue_results
wandb: â­ï¸ View project at https://wandb.ai/l-zijie/huggingface
wandb: ðŸš€ View run at https://wandb.ai/l-zijie/huggingface/runs/rb2dcy5o
  0%|          | 0/3148 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  0%|          | 1/3148 [00:08<7:50:04,  8.96s/it]  0%|          | 2/3148 [00:17<7:41:44,  8.81s/it]  0%|          | 3/3148 [00:24<7:01:30,  8.04s/it]  0%|          | 4/3148 [00:31<6:42:25,  7.68s/it]  0%|          | 5/3148 [00:39<6:32:11,  7.49s/it]  0%|          | 6/3148 [00:46<6:25:47,  7.37s/it]  0%|          | 7/3148 [00:53<6:22:09,  7.30s/it]  0%|          | 8/3148 [01:00<6:19:34,  7.25s/it]  0%|          | 9/3148 [01:07<6:17:10,  7.21s/it]  0%|          | 10/3148 [01:14<6:15:48,  7.19s/it]                                                   {'loss': 1.6668, 'grad_norm': 1.19056236743927, 'learning_rate': 5.714285714285715e-07, 'epoch': 0.01}
  0%|          | 10/3148 [01:14<6:15:48,  7.19s/it]  0%|          | 11/3148 [01:21<6:14:43,  7.17s/it]  0%|          | 12/3148 [01:30<6:36:03,  7.58s/it]  0%|          | 13/3148 [01:39<6:53:26,  7.91s/it]  0%|          | 14/3148 [01:46<6:41:22,  7.68s/it]  0%|          | 15/3148 [01:54<6:54:27,  7.94s/it]  1%|          | 16/3148 [02:01<6:42:22,  7.71s/it]  1%|          | 17/3148 [02:10<6:54:32,  7.94s/it]  1%|          | 18/3148 [02:17<6:40:34,  7.68s/it]  1%|          | 19/3148 [02:24<6:30:47,  7.49s/it]  1%|          | 20/3148 [02:33<6:48:34,  7.84s/it]                                                   {'loss': 1.613, 'grad_norm': 1.4239970445632935, 'learning_rate': 1.2063492063492065e-06, 'epoch': 0.01}
  1%|          | 20/3148 [02:33<6:48:34,  7.84s/it]  1%|          | 21/3148 [02:40<6:37:03,  7.62s/it]  1%|          | 22/3148 [02:47<6:29:01,  7.47s/it]W1230 23:56:43.662000 1742636 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1742727 closing signal SIGTERM
W1230 23:56:43.663000 1742636 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1742728 closing signal SIGTERM
W1230 23:56:43.663000 1742636 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1742730 closing signal SIGTERM
E1230 23:56:44.156000 1742636 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 2 (pid: 1742729) of binary: /home/xinyuzh/anaconda3/envs/meditron/bin/python
Traceback (most recent call last):
  File "/home/xinyuzh/anaconda3/envs/meditron/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/xinyuzh/anaconda3/envs/meditron/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
tune_umls_dialogue.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-30_23:56:43
  host      : unites4.cs.unc.edu
  rank      : 2 (local_rank: 2)
  exitcode  : -9 (pid: 1742729)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 1742729
========================================================
