{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9997617345723135,
  "eval_steps": 500,
  "global_step": 12590,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015884361845762845,
      "grad_norm": 1.0540924072265625,
      "learning_rate": 7.942811755361398e-07,
      "loss": 1.4299,
      "step": 100
    },
    {
      "epoch": 0.03176872369152569,
      "grad_norm": 1.0976251363754272,
      "learning_rate": 1.5885623510722797e-06,
      "loss": 1.4158,
      "step": 200
    },
    {
      "epoch": 0.04765308553728854,
      "grad_norm": 1.500077486038208,
      "learning_rate": 2.3828435266084195e-06,
      "loss": 1.4035,
      "step": 300
    },
    {
      "epoch": 0.06353744738305138,
      "grad_norm": 1.3589439392089844,
      "learning_rate": 3.1771247021445594e-06,
      "loss": 1.3005,
      "step": 400
    },
    {
      "epoch": 0.07942180922881423,
      "grad_norm": 1.2194441556930542,
      "learning_rate": 3.971405877680699e-06,
      "loss": 1.2036,
      "step": 500
    },
    {
      "epoch": 0.09530617107457708,
      "grad_norm": 0.9292675852775574,
      "learning_rate": 4.765687053216839e-06,
      "loss": 1.1311,
      "step": 600
    },
    {
      "epoch": 0.11119053292033992,
      "grad_norm": 0.8580686450004578,
      "learning_rate": 5.559968228752979e-06,
      "loss": 1.0306,
      "step": 700
    },
    {
      "epoch": 0.12707489476610276,
      "grad_norm": 1.013412356376648,
      "learning_rate": 6.354249404289119e-06,
      "loss": 0.9608,
      "step": 800
    },
    {
      "epoch": 0.14295925661186562,
      "grad_norm": 1.0479885339736938,
      "learning_rate": 7.1485305798252594e-06,
      "loss": 0.9025,
      "step": 900
    },
    {
      "epoch": 0.15884361845762845,
      "grad_norm": 1.1684379577636719,
      "learning_rate": 7.942811755361398e-06,
      "loss": 0.8703,
      "step": 1000
    },
    {
      "epoch": 0.17472798030339132,
      "grad_norm": 1.3431590795516968,
      "learning_rate": 8.737092930897538e-06,
      "loss": 0.8386,
      "step": 1100
    },
    {
      "epoch": 0.19061234214915415,
      "grad_norm": 1.1036484241485596,
      "learning_rate": 9.531374106433678e-06,
      "loss": 0.7938,
      "step": 1200
    },
    {
      "epoch": 0.206496703994917,
      "grad_norm": 1.0437489748001099,
      "learning_rate": 9.999676952554087e-06,
      "loss": 0.7948,
      "step": 1300
    },
    {
      "epoch": 0.22238106584067985,
      "grad_norm": 0.8207656741142273,
      "learning_rate": 9.996179799215276e-06,
      "loss": 0.7903,
      "step": 1400
    },
    {
      "epoch": 0.2382654276864427,
      "grad_norm": 1.3595064878463745,
      "learning_rate": 9.988842272019444e-06,
      "loss": 0.767,
      "step": 1500
    },
    {
      "epoch": 0.2541497895322055,
      "grad_norm": 1.4341305494308472,
      "learning_rate": 9.977670011045358e-06,
      "loss": 0.7331,
      "step": 1600
    },
    {
      "epoch": 0.2700341513779684,
      "grad_norm": 1.3767449855804443,
      "learning_rate": 9.962671603986156e-06,
      "loss": 0.7596,
      "step": 1700
    },
    {
      "epoch": 0.28591851322373124,
      "grad_norm": 1.178406834602356,
      "learning_rate": 9.943858579548308e-06,
      "loss": 0.723,
      "step": 1800
    },
    {
      "epoch": 0.3018028750694941,
      "grad_norm": 1.532008409500122,
      "learning_rate": 9.921245398589931e-06,
      "loss": 0.7197,
      "step": 1900
    },
    {
      "epoch": 0.3176872369152569,
      "grad_norm": 1.348900556564331,
      "learning_rate": 9.89484944300529e-06,
      "loss": 0.71,
      "step": 2000
    },
    {
      "epoch": 0.33357159876101977,
      "grad_norm": 1.6001425981521606,
      "learning_rate": 9.864691002363977e-06,
      "loss": 0.7013,
      "step": 2100
    },
    {
      "epoch": 0.34945596060678263,
      "grad_norm": 1.4941242933273315,
      "learning_rate": 9.83079325831511e-06,
      "loss": 0.7094,
      "step": 2200
    },
    {
      "epoch": 0.3653403224525455,
      "grad_norm": 1.835553765296936,
      "learning_rate": 9.79318226676846e-06,
      "loss": 0.7083,
      "step": 2300
    },
    {
      "epoch": 0.3812246842983083,
      "grad_norm": 1.6630287170410156,
      "learning_rate": 9.75188693786627e-06,
      "loss": 0.7174,
      "step": 2400
    },
    {
      "epoch": 0.39710904614407116,
      "grad_norm": 1.6925855875015259,
      "learning_rate": 9.706939013761123e-06,
      "loss": 0.685,
      "step": 2500
    },
    {
      "epoch": 0.412993407989834,
      "grad_norm": 2.1006014347076416,
      "learning_rate": 9.658373044216963e-06,
      "loss": 0.6978,
      "step": 2600
    },
    {
      "epoch": 0.42887776983559683,
      "grad_norm": 1.6590458154678345,
      "learning_rate": 9.606226360051989e-06,
      "loss": 0.7237,
      "step": 2700
    },
    {
      "epoch": 0.4447621316813597,
      "grad_norm": 2.220579147338867,
      "learning_rate": 9.55053904444388e-06,
      "loss": 0.6807,
      "step": 2800
    },
    {
      "epoch": 0.46064649352712256,
      "grad_norm": 1.7561720609664917,
      "learning_rate": 9.491353902119364e-06,
      "loss": 0.6904,
      "step": 2900
    },
    {
      "epoch": 0.4765308553728854,
      "grad_norm": 1.9840741157531738,
      "learning_rate": 9.428716426451875e-06,
      "loss": 0.6771,
      "step": 3000
    },
    {
      "epoch": 0.4924152172186482,
      "grad_norm": 2.163879156112671,
      "learning_rate": 9.362674764492493e-06,
      "loss": 0.671,
      "step": 3100
    },
    {
      "epoch": 0.508299579064411,
      "grad_norm": 2.0388455390930176,
      "learning_rate": 9.293279679961156e-06,
      "loss": 0.6481,
      "step": 3200
    },
    {
      "epoch": 0.524183940910174,
      "grad_norm": 1.8649574518203735,
      "learning_rate": 9.220584514226495e-06,
      "loss": 0.7098,
      "step": 3300
    },
    {
      "epoch": 0.5400683027559368,
      "grad_norm": 1.5720851421356201,
      "learning_rate": 9.144645145304364e-06,
      "loss": 0.6767,
      "step": 3400
    },
    {
      "epoch": 0.5559526646016997,
      "grad_norm": 2.2909369468688965,
      "learning_rate": 9.06551994490652e-06,
      "loss": 0.6638,
      "step": 3500
    },
    {
      "epoch": 0.5718370264474625,
      "grad_norm": 1.8785918951034546,
      "learning_rate": 8.983269733572506e-06,
      "loss": 0.6774,
      "step": 3600
    },
    {
      "epoch": 0.5877213882932253,
      "grad_norm": 1.8098526000976562,
      "learning_rate": 8.897957733919206e-06,
      "loss": 0.6637,
      "step": 3700
    },
    {
      "epoch": 0.6036057501389882,
      "grad_norm": 1.7898446321487427,
      "learning_rate": 8.809649522044029e-06,
      "loss": 0.6506,
      "step": 3800
    },
    {
      "epoch": 0.619490111984751,
      "grad_norm": 2.1713404655456543,
      "learning_rate": 8.718412977119031e-06,
      "loss": 0.6575,
      "step": 3900
    },
    {
      "epoch": 0.6353744738305138,
      "grad_norm": 1.9479540586471558,
      "learning_rate": 8.624318229214792e-06,
      "loss": 0.6708,
      "step": 4000
    },
    {
      "epoch": 0.6512588356762767,
      "grad_norm": 3.574620246887207,
      "learning_rate": 8.52743760539408e-06,
      "loss": 0.656,
      "step": 4100
    },
    {
      "epoch": 0.6671431975220395,
      "grad_norm": 2.048386812210083,
      "learning_rate": 8.427845574116783e-06,
      "loss": 0.6605,
      "step": 4200
    },
    {
      "epoch": 0.6830275593678024,
      "grad_norm": 2.0043842792510986,
      "learning_rate": 8.325618687998828e-06,
      "loss": 0.6535,
      "step": 4300
    },
    {
      "epoch": 0.6989119212135653,
      "grad_norm": 2.18538761138916,
      "learning_rate": 8.2208355249691e-06,
      "loss": 0.6635,
      "step": 4400
    },
    {
      "epoch": 0.7147962830593281,
      "grad_norm": 2.0152485370635986,
      "learning_rate": 8.113576627869551e-06,
      "loss": 0.6541,
      "step": 4500
    },
    {
      "epoch": 0.730680644905091,
      "grad_norm": 2.2526161670684814,
      "learning_rate": 8.003924442544991e-06,
      "loss": 0.6761,
      "step": 4600
    },
    {
      "epoch": 0.7465650067508538,
      "grad_norm": 2.1790482997894287,
      "learning_rate": 7.891963254470084e-06,
      "loss": 0.6129,
      "step": 4700
    },
    {
      "epoch": 0.7624493685966166,
      "grad_norm": 1.8862287998199463,
      "learning_rate": 7.7777791239623e-06,
      "loss": 0.6719,
      "step": 4800
    },
    {
      "epoch": 0.7783337304423795,
      "grad_norm": 1.9105253219604492,
      "learning_rate": 7.661459820030632e-06,
      "loss": 0.658,
      "step": 4900
    },
    {
      "epoch": 0.7942180922881423,
      "grad_norm": 2.0313968658447266,
      "learning_rate": 7.543094752910865e-06,
      "loss": 0.6758,
      "step": 5000
    },
    {
      "epoch": 0.8101024541339051,
      "grad_norm": 2.360053300857544,
      "learning_rate": 7.422774905339332e-06,
      "loss": 0.6578,
      "step": 5100
    },
    {
      "epoch": 0.825986815979668,
      "grad_norm": 2.550741672515869,
      "learning_rate": 7.300592762617937e-06,
      "loss": 0.6826,
      "step": 5200
    },
    {
      "epoch": 0.8418711778254309,
      "grad_norm": 2.187443494796753,
      "learning_rate": 7.1766422415242095e-06,
      "loss": 0.6443,
      "step": 5300
    },
    {
      "epoch": 0.8577555396711937,
      "grad_norm": 2.2169923782348633,
      "learning_rate": 7.051018618121045e-06,
      "loss": 0.6621,
      "step": 5400
    },
    {
      "epoch": 0.8736399015169566,
      "grad_norm": 3.9397876262664795,
      "learning_rate": 6.9238184545216e-06,
      "loss": 0.6677,
      "step": 5500
    },
    {
      "epoch": 0.8895242633627194,
      "grad_norm": 2.6476786136627197,
      "learning_rate": 6.795139524665672e-06,
      "loss": 0.6539,
      "step": 5600
    },
    {
      "epoch": 0.9054086252084822,
      "grad_norm": 1.9348840713500977,
      "learning_rate": 6.665080739164576e-06,
      "loss": 0.6442,
      "step": 5700
    },
    {
      "epoch": 0.9212929870542451,
      "grad_norm": 2.0530927181243896,
      "learning_rate": 6.533742069272302e-06,
      "loss": 0.6528,
      "step": 5800
    },
    {
      "epoch": 0.9371773489000079,
      "grad_norm": 2.226409912109375,
      "learning_rate": 6.401224470041424e-06,
      "loss": 0.6352,
      "step": 5900
    },
    {
      "epoch": 0.9530617107457708,
      "grad_norm": 2.247610092163086,
      "learning_rate": 6.26762980272276e-06,
      "loss": 0.6369,
      "step": 6000
    },
    {
      "epoch": 0.9689460725915336,
      "grad_norm": 1.9023547172546387,
      "learning_rate": 6.133060756468509e-06,
      "loss": 0.6488,
      "step": 6100
    },
    {
      "epoch": 0.9848304344372965,
      "grad_norm": 3.473444938659668,
      "learning_rate": 5.997620769398991e-06,
      "loss": 0.6429,
      "step": 6200
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6273961067199707,
      "eval_runtime": 588.0625,
      "eval_samples_per_second": 18.889,
      "eval_steps_per_second": 2.362,
      "step": 6296
    },
    {
      "epoch": 1.0006353744738306,
      "grad_norm": 2.457113742828369,
      "learning_rate": 5.86141394909368e-06,
      "loss": 0.645,
      "step": 6300
    },
    {
      "epoch": 1.0165197363195935,
      "grad_norm": 1.770970344543457,
      "learning_rate": 5.7245449925676744e-06,
      "loss": 0.6514,
      "step": 6400
    },
    {
      "epoch": 1.0324040981653562,
      "grad_norm": 2.1827497482299805,
      "learning_rate": 5.587119105795056e-06,
      "loss": 0.6166,
      "step": 6500
    },
    {
      "epoch": 1.048288460011119,
      "grad_norm": 1.821062445640564,
      "learning_rate": 5.449241922841061e-06,
      "loss": 0.6374,
      "step": 6600
    },
    {
      "epoch": 1.064172821856882,
      "grad_norm": 2.92978835105896,
      "learning_rate": 5.311019424665179e-06,
      "loss": 0.6306,
      "step": 6700
    },
    {
      "epoch": 1.0800571837026447,
      "grad_norm": 2.2246954441070557,
      "learning_rate": 5.172557857657609e-06,
      "loss": 0.662,
      "step": 6800
    },
    {
      "epoch": 1.0959415455484076,
      "grad_norm": 2.3016602993011475,
      "learning_rate": 5.033963651971685e-06,
      "loss": 0.6301,
      "step": 6900
    },
    {
      "epoch": 1.1118259073941705,
      "grad_norm": 2.3349831104278564,
      "learning_rate": 4.8953433397150704e-06,
      "loss": 0.6557,
      "step": 7000
    },
    {
      "epoch": 1.1277102692399332,
      "grad_norm": 2.1477437019348145,
      "learning_rate": 4.756803473062551e-06,
      "loss": 0.633,
      "step": 7100
    },
    {
      "epoch": 1.1435946310856961,
      "grad_norm": 1.9859721660614014,
      "learning_rate": 4.618450542353433e-06,
      "loss": 0.6287,
      "step": 7200
    },
    {
      "epoch": 1.159478992931459,
      "grad_norm": 2.2932817935943604,
      "learning_rate": 4.480390894236455e-06,
      "loss": 0.6247,
      "step": 7300
    },
    {
      "epoch": 1.1753633547772218,
      "grad_norm": 2.564765691757202,
      "learning_rate": 4.342730649925151e-06,
      "loss": 0.6494,
      "step": 7400
    },
    {
      "epoch": 1.1912477166229847,
      "grad_norm": 3.149693727493286,
      "learning_rate": 4.205575623626508e-06,
      "loss": 0.6545,
      "step": 7500
    },
    {
      "epoch": 1.2071320784687476,
      "grad_norm": 1.87351393699646,
      "learning_rate": 4.06903124120559e-06,
      "loss": 0.6376,
      "step": 7600
    },
    {
      "epoch": 1.2230164403145103,
      "grad_norm": 2.2133734226226807,
      "learning_rate": 3.933202459148682e-06,
      "loss": 0.6281,
      "step": 7700
    },
    {
      "epoch": 1.2389008021602732,
      "grad_norm": 1.6343411207199097,
      "learning_rate": 3.7981936838872187e-06,
      "loss": 0.6332,
      "step": 7800
    },
    {
      "epoch": 1.2547851640060361,
      "grad_norm": 2.3640050888061523,
      "learning_rate": 3.664108691544523e-06,
      "loss": 0.6554,
      "step": 7900
    },
    {
      "epoch": 1.2706695258517988,
      "grad_norm": 2.223572015762329,
      "learning_rate": 3.5310505481670338e-06,
      "loss": 0.6449,
      "step": 8000
    },
    {
      "epoch": 1.2865538876975617,
      "grad_norm": 2.556910514831543,
      "learning_rate": 3.399121530501353e-06,
      "loss": 0.6435,
      "step": 8100
    },
    {
      "epoch": 1.3024382495433247,
      "grad_norm": 2.1496970653533936,
      "learning_rate": 3.268423047377984e-06,
      "loss": 0.6517,
      "step": 8200
    },
    {
      "epoch": 1.3183226113890876,
      "grad_norm": 2.7762608528137207,
      "learning_rate": 3.1390555617622125e-06,
      "loss": 0.6308,
      "step": 8300
    },
    {
      "epoch": 1.3342069732348503,
      "grad_norm": 1.9091601371765137,
      "learning_rate": 3.011118513532043e-06,
      "loss": 0.638,
      "step": 8400
    },
    {
      "epoch": 1.3500913350806132,
      "grad_norm": 2.2206900119781494,
      "learning_rate": 2.884710243042528e-06,
      "loss": 0.6353,
      "step": 8500
    },
    {
      "epoch": 1.3659756969263759,
      "grad_norm": 2.7501518726348877,
      "learning_rate": 2.759927915535272e-06,
      "loss": 0.6283,
      "step": 8600
    },
    {
      "epoch": 1.3818600587721388,
      "grad_norm": 2.014137029647827,
      "learning_rate": 2.6368674464512013e-06,
      "loss": 0.6449,
      "step": 8700
    },
    {
      "epoch": 1.3977444206179017,
      "grad_norm": 2.7993292808532715,
      "learning_rate": 2.515623427703998e-06,
      "loss": 0.6235,
      "step": 8800
    },
    {
      "epoch": 1.4136287824636646,
      "grad_norm": 2.8376717567443848,
      "learning_rate": 2.3962890549708824e-06,
      "loss": 0.6295,
      "step": 8900
    },
    {
      "epoch": 1.4295131443094273,
      "grad_norm": 2.5259852409362793,
      "learning_rate": 2.2789560560566398e-06,
      "loss": 0.6212,
      "step": 9000
    },
    {
      "epoch": 1.4453975061551902,
      "grad_norm": 2.6922032833099365,
      "learning_rate": 2.163714620385934e-06,
      "loss": 0.6281,
      "step": 9100
    },
    {
      "epoch": 1.461281868000953,
      "grad_norm": 1.9724183082580566,
      "learning_rate": 2.0506533296781106e-06,
      "loss": 0.6405,
      "step": 9200
    },
    {
      "epoch": 1.4771662298467159,
      "grad_norm": 2.356656074523926,
      "learning_rate": 1.9398590898578034e-06,
      "loss": 0.6184,
      "step": 9300
    },
    {
      "epoch": 1.4930505916924788,
      "grad_norm": 2.8820266723632812,
      "learning_rate": 1.83141706425364e-06,
      "loss": 0.6403,
      "step": 9400
    },
    {
      "epoch": 1.5089349535382417,
      "grad_norm": 2.278103828430176,
      "learning_rate": 1.725410608136417e-06,
      "loss": 0.6008,
      "step": 9500
    },
    {
      "epoch": 1.5248193153840044,
      "grad_norm": 2.708470582962036,
      "learning_rate": 1.6219212046470785e-06,
      "loss": 0.637,
      "step": 9600
    },
    {
      "epoch": 1.5407036772297673,
      "grad_norm": 1.5811080932617188,
      "learning_rate": 1.5210284021637084e-06,
      "loss": 0.6447,
      "step": 9700
    },
    {
      "epoch": 1.55658803907553,
      "grad_norm": 1.9594528675079346,
      "learning_rate": 1.4228097531557089e-06,
      "loss": 0.6358,
      "step": 9800
    },
    {
      "epoch": 1.572472400921293,
      "grad_norm": 2.5705809593200684,
      "learning_rate": 1.327340754572166e-06,
      "loss": 0.6151,
      "step": 9900
    },
    {
      "epoch": 1.5883567627670558,
      "grad_norm": 2.2184059619903564,
      "learning_rate": 1.234694789810208e-06,
      "loss": 0.6197,
      "step": 10000
    },
    {
      "epoch": 1.6042411246128188,
      "grad_norm": 2.047858715057373,
      "learning_rate": 1.144943072307963e-06,
      "loss": 0.6452,
      "step": 10100
    },
    {
      "epoch": 1.6201254864585817,
      "grad_norm": 2.3968727588653564,
      "learning_rate": 1.0581545908055062e-06,
      "loss": 0.6182,
      "step": 10200
    },
    {
      "epoch": 1.6360098483043444,
      "grad_norm": 2.4173848628997803,
      "learning_rate": 9.743960563158194e-07,
      "loss": 0.635,
      "step": 10300
    },
    {
      "epoch": 1.651894210150107,
      "grad_norm": 2.9466123580932617,
      "learning_rate": 8.937318508465725e-07,
      "loss": 0.6069,
      "step": 10400
    },
    {
      "epoch": 1.66777857199587,
      "grad_norm": 2.5123190879821777,
      "learning_rate": 8.162239779121167e-07,
      "loss": 0.6287,
      "step": 10500
    },
    {
      "epoch": 1.683662933841633,
      "grad_norm": 2.672945737838745,
      "learning_rate": 7.419320148737358e-07,
      "loss": 0.6322,
      "step": 10600
    },
    {
      "epoch": 1.6995472956873958,
      "grad_norm": 2.4411516189575195,
      "learning_rate": 6.709130671447872e-07,
      "loss": 0.6435,
      "step": 10700
    },
    {
      "epoch": 1.7154316575331587,
      "grad_norm": 2.3832571506500244,
      "learning_rate": 6.032217242959348e-07,
      "loss": 0.651,
      "step": 10800
    },
    {
      "epoch": 1.7313160193789214,
      "grad_norm": 3.14103364944458,
      "learning_rate": 5.389100180942248e-07,
      "loss": 0.634,
      "step": 10900
    },
    {
      "epoch": 1.7472003812246844,
      "grad_norm": 2.1346235275268555,
      "learning_rate": 4.780273825082343e-07,
      "loss": 0.6448,
      "step": 11000
    },
    {
      "epoch": 1.763084743070447,
      "grad_norm": 2.4799611568450928,
      "learning_rate": 4.20620615710054e-07,
      "loss": 0.6176,
      "step": 11100
    },
    {
      "epoch": 1.77896910491621,
      "grad_norm": 2.4133169651031494,
      "learning_rate": 3.667338441033158e-07,
      "loss": 0.6215,
      "step": 11200
    },
    {
      "epoch": 1.7948534667619729,
      "grad_norm": 2.69500470161438,
      "learning_rate": 3.16408488404894e-07,
      "loss": 0.6319,
      "step": 11300
    },
    {
      "epoch": 1.8107378286077358,
      "grad_norm": 1.762656807899475,
      "learning_rate": 2.69683231806373e-07,
      "loss": 0.6495,
      "step": 11400
    },
    {
      "epoch": 1.8266221904534985,
      "grad_norm": 2.6055867671966553,
      "learning_rate": 2.2659399023974904e-07,
      "loss": 0.6203,
      "step": 11500
    },
    {
      "epoch": 1.8425065522992614,
      "grad_norm": 2.5730204582214355,
      "learning_rate": 1.8717388477021204e-07,
      "loss": 0.6276,
      "step": 11600
    },
    {
      "epoch": 1.858390914145024,
      "grad_norm": 3.4228641986846924,
      "learning_rate": 1.5145321613724063e-07,
      "loss": 0.6131,
      "step": 11700
    },
    {
      "epoch": 1.874275275990787,
      "grad_norm": 2.4955577850341797,
      "learning_rate": 1.1945944146357414e-07,
      "loss": 0.6343,
      "step": 11800
    },
    {
      "epoch": 1.89015963783655,
      "grad_norm": 2.0464091300964355,
      "learning_rate": 9.121715314996393e-08,
      "loss": 0.613,
      "step": 11900
    },
    {
      "epoch": 1.9060439996823129,
      "grad_norm": 2.9963314533233643,
      "learning_rate": 6.674805997192502e-08,
      "loss": 0.6209,
      "step": 12000
    },
    {
      "epoch": 1.9219283615280756,
      "grad_norm": 2.438429355621338,
      "learning_rate": 4.607097039302899e-08,
      "loss": 0.6051,
      "step": 12100
    },
    {
      "epoch": 1.9378127233738385,
      "grad_norm": 2.8699393272399902,
      "learning_rate": 2.920177810754876e-08,
      "loss": 0.6176,
      "step": 12200
    },
    {
      "epoch": 1.9536970852196012,
      "grad_norm": 2.5297927856445312,
      "learning_rate": 1.615344982357714e-08,
      "loss": 0.6367,
      "step": 12300
    },
    {
      "epoch": 1.969581447065364,
      "grad_norm": 2.920132637023926,
      "learning_rate": 6.936015296014065e-09,
      "loss": 0.6529,
      "step": 12400
    },
    {
      "epoch": 1.985465808911127,
      "grad_norm": 2.7110142707824707,
      "learning_rate": 1.5565596170730169e-09,
      "loss": 0.5972,
      "step": 12500
    },
    {
      "epoch": 1.9997617345723135,
      "eval_loss": 0.6152696013450623,
      "eval_runtime": 589.2659,
      "eval_samples_per_second": 18.851,
      "eval_steps_per_second": 2.357,
      "step": 12590
    }
  ],
  "logging_steps": 100,
  "max_steps": 12590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9706228081153802e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
