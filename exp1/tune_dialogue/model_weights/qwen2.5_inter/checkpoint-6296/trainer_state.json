{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 6296,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015884361845762845,
      "grad_norm": 1.0540924072265625,
      "learning_rate": 7.942811755361398e-07,
      "loss": 1.4299,
      "step": 100
    },
    {
      "epoch": 0.03176872369152569,
      "grad_norm": 1.0976251363754272,
      "learning_rate": 1.5885623510722797e-06,
      "loss": 1.4158,
      "step": 200
    },
    {
      "epoch": 0.04765308553728854,
      "grad_norm": 1.500077486038208,
      "learning_rate": 2.3828435266084195e-06,
      "loss": 1.4035,
      "step": 300
    },
    {
      "epoch": 0.06353744738305138,
      "grad_norm": 1.3589439392089844,
      "learning_rate": 3.1771247021445594e-06,
      "loss": 1.3005,
      "step": 400
    },
    {
      "epoch": 0.07942180922881423,
      "grad_norm": 1.2194441556930542,
      "learning_rate": 3.971405877680699e-06,
      "loss": 1.2036,
      "step": 500
    },
    {
      "epoch": 0.09530617107457708,
      "grad_norm": 0.9292675852775574,
      "learning_rate": 4.765687053216839e-06,
      "loss": 1.1311,
      "step": 600
    },
    {
      "epoch": 0.11119053292033992,
      "grad_norm": 0.8580686450004578,
      "learning_rate": 5.559968228752979e-06,
      "loss": 1.0306,
      "step": 700
    },
    {
      "epoch": 0.12707489476610276,
      "grad_norm": 1.013412356376648,
      "learning_rate": 6.354249404289119e-06,
      "loss": 0.9608,
      "step": 800
    },
    {
      "epoch": 0.14295925661186562,
      "grad_norm": 1.0479885339736938,
      "learning_rate": 7.1485305798252594e-06,
      "loss": 0.9025,
      "step": 900
    },
    {
      "epoch": 0.15884361845762845,
      "grad_norm": 1.1684379577636719,
      "learning_rate": 7.942811755361398e-06,
      "loss": 0.8703,
      "step": 1000
    },
    {
      "epoch": 0.17472798030339132,
      "grad_norm": 1.3431590795516968,
      "learning_rate": 8.737092930897538e-06,
      "loss": 0.8386,
      "step": 1100
    },
    {
      "epoch": 0.19061234214915415,
      "grad_norm": 1.1036484241485596,
      "learning_rate": 9.531374106433678e-06,
      "loss": 0.7938,
      "step": 1200
    },
    {
      "epoch": 0.206496703994917,
      "grad_norm": 1.0437489748001099,
      "learning_rate": 9.999676952554087e-06,
      "loss": 0.7948,
      "step": 1300
    },
    {
      "epoch": 0.22238106584067985,
      "grad_norm": 0.8207656741142273,
      "learning_rate": 9.996179799215276e-06,
      "loss": 0.7903,
      "step": 1400
    },
    {
      "epoch": 0.2382654276864427,
      "grad_norm": 1.3595064878463745,
      "learning_rate": 9.988842272019444e-06,
      "loss": 0.767,
      "step": 1500
    },
    {
      "epoch": 0.2541497895322055,
      "grad_norm": 1.4341305494308472,
      "learning_rate": 9.977670011045358e-06,
      "loss": 0.7331,
      "step": 1600
    },
    {
      "epoch": 0.2700341513779684,
      "grad_norm": 1.3767449855804443,
      "learning_rate": 9.962671603986156e-06,
      "loss": 0.7596,
      "step": 1700
    },
    {
      "epoch": 0.28591851322373124,
      "grad_norm": 1.178406834602356,
      "learning_rate": 9.943858579548308e-06,
      "loss": 0.723,
      "step": 1800
    },
    {
      "epoch": 0.3018028750694941,
      "grad_norm": 1.532008409500122,
      "learning_rate": 9.921245398589931e-06,
      "loss": 0.7197,
      "step": 1900
    },
    {
      "epoch": 0.3176872369152569,
      "grad_norm": 1.348900556564331,
      "learning_rate": 9.89484944300529e-06,
      "loss": 0.71,
      "step": 2000
    },
    {
      "epoch": 0.33357159876101977,
      "grad_norm": 1.6001425981521606,
      "learning_rate": 9.864691002363977e-06,
      "loss": 0.7013,
      "step": 2100
    },
    {
      "epoch": 0.34945596060678263,
      "grad_norm": 1.4941242933273315,
      "learning_rate": 9.83079325831511e-06,
      "loss": 0.7094,
      "step": 2200
    },
    {
      "epoch": 0.3653403224525455,
      "grad_norm": 1.835553765296936,
      "learning_rate": 9.79318226676846e-06,
      "loss": 0.7083,
      "step": 2300
    },
    {
      "epoch": 0.3812246842983083,
      "grad_norm": 1.6630287170410156,
      "learning_rate": 9.75188693786627e-06,
      "loss": 0.7174,
      "step": 2400
    },
    {
      "epoch": 0.39710904614407116,
      "grad_norm": 1.6925855875015259,
      "learning_rate": 9.706939013761123e-06,
      "loss": 0.685,
      "step": 2500
    },
    {
      "epoch": 0.412993407989834,
      "grad_norm": 2.1006014347076416,
      "learning_rate": 9.658373044216963e-06,
      "loss": 0.6978,
      "step": 2600
    },
    {
      "epoch": 0.42887776983559683,
      "grad_norm": 1.6590458154678345,
      "learning_rate": 9.606226360051989e-06,
      "loss": 0.7237,
      "step": 2700
    },
    {
      "epoch": 0.4447621316813597,
      "grad_norm": 2.220579147338867,
      "learning_rate": 9.55053904444388e-06,
      "loss": 0.6807,
      "step": 2800
    },
    {
      "epoch": 0.46064649352712256,
      "grad_norm": 1.7561720609664917,
      "learning_rate": 9.491353902119364e-06,
      "loss": 0.6904,
      "step": 2900
    },
    {
      "epoch": 0.4765308553728854,
      "grad_norm": 1.9840741157531738,
      "learning_rate": 9.428716426451875e-06,
      "loss": 0.6771,
      "step": 3000
    },
    {
      "epoch": 0.4924152172186482,
      "grad_norm": 2.163879156112671,
      "learning_rate": 9.362674764492493e-06,
      "loss": 0.671,
      "step": 3100
    },
    {
      "epoch": 0.508299579064411,
      "grad_norm": 2.0388455390930176,
      "learning_rate": 9.293279679961156e-06,
      "loss": 0.6481,
      "step": 3200
    },
    {
      "epoch": 0.524183940910174,
      "grad_norm": 1.8649574518203735,
      "learning_rate": 9.220584514226495e-06,
      "loss": 0.7098,
      "step": 3300
    },
    {
      "epoch": 0.5400683027559368,
      "grad_norm": 1.5720851421356201,
      "learning_rate": 9.144645145304364e-06,
      "loss": 0.6767,
      "step": 3400
    },
    {
      "epoch": 0.5559526646016997,
      "grad_norm": 2.2909369468688965,
      "learning_rate": 9.06551994490652e-06,
      "loss": 0.6638,
      "step": 3500
    },
    {
      "epoch": 0.5718370264474625,
      "grad_norm": 1.8785918951034546,
      "learning_rate": 8.983269733572506e-06,
      "loss": 0.6774,
      "step": 3600
    },
    {
      "epoch": 0.5877213882932253,
      "grad_norm": 1.8098526000976562,
      "learning_rate": 8.897957733919206e-06,
      "loss": 0.6637,
      "step": 3700
    },
    {
      "epoch": 0.6036057501389882,
      "grad_norm": 1.7898446321487427,
      "learning_rate": 8.809649522044029e-06,
      "loss": 0.6506,
      "step": 3800
    },
    {
      "epoch": 0.619490111984751,
      "grad_norm": 2.1713404655456543,
      "learning_rate": 8.718412977119031e-06,
      "loss": 0.6575,
      "step": 3900
    },
    {
      "epoch": 0.6353744738305138,
      "grad_norm": 1.9479540586471558,
      "learning_rate": 8.624318229214792e-06,
      "loss": 0.6708,
      "step": 4000
    },
    {
      "epoch": 0.6512588356762767,
      "grad_norm": 3.574620246887207,
      "learning_rate": 8.52743760539408e-06,
      "loss": 0.656,
      "step": 4100
    },
    {
      "epoch": 0.6671431975220395,
      "grad_norm": 2.048386812210083,
      "learning_rate": 8.427845574116783e-06,
      "loss": 0.6605,
      "step": 4200
    },
    {
      "epoch": 0.6830275593678024,
      "grad_norm": 2.0043842792510986,
      "learning_rate": 8.325618687998828e-06,
      "loss": 0.6535,
      "step": 4300
    },
    {
      "epoch": 0.6989119212135653,
      "grad_norm": 2.18538761138916,
      "learning_rate": 8.2208355249691e-06,
      "loss": 0.6635,
      "step": 4400
    },
    {
      "epoch": 0.7147962830593281,
      "grad_norm": 2.0152485370635986,
      "learning_rate": 8.113576627869551e-06,
      "loss": 0.6541,
      "step": 4500
    },
    {
      "epoch": 0.730680644905091,
      "grad_norm": 2.2526161670684814,
      "learning_rate": 8.003924442544991e-06,
      "loss": 0.6761,
      "step": 4600
    },
    {
      "epoch": 0.7465650067508538,
      "grad_norm": 2.1790482997894287,
      "learning_rate": 7.891963254470084e-06,
      "loss": 0.6129,
      "step": 4700
    },
    {
      "epoch": 0.7624493685966166,
      "grad_norm": 1.8862287998199463,
      "learning_rate": 7.7777791239623e-06,
      "loss": 0.6719,
      "step": 4800
    },
    {
      "epoch": 0.7783337304423795,
      "grad_norm": 1.9105253219604492,
      "learning_rate": 7.661459820030632e-06,
      "loss": 0.658,
      "step": 4900
    },
    {
      "epoch": 0.7942180922881423,
      "grad_norm": 2.0313968658447266,
      "learning_rate": 7.543094752910865e-06,
      "loss": 0.6758,
      "step": 5000
    },
    {
      "epoch": 0.8101024541339051,
      "grad_norm": 2.360053300857544,
      "learning_rate": 7.422774905339332e-06,
      "loss": 0.6578,
      "step": 5100
    },
    {
      "epoch": 0.825986815979668,
      "grad_norm": 2.550741672515869,
      "learning_rate": 7.300592762617937e-06,
      "loss": 0.6826,
      "step": 5200
    },
    {
      "epoch": 0.8418711778254309,
      "grad_norm": 2.187443494796753,
      "learning_rate": 7.1766422415242095e-06,
      "loss": 0.6443,
      "step": 5300
    },
    {
      "epoch": 0.8577555396711937,
      "grad_norm": 2.2169923782348633,
      "learning_rate": 7.051018618121045e-06,
      "loss": 0.6621,
      "step": 5400
    },
    {
      "epoch": 0.8736399015169566,
      "grad_norm": 3.9397876262664795,
      "learning_rate": 6.9238184545216e-06,
      "loss": 0.6677,
      "step": 5500
    },
    {
      "epoch": 0.8895242633627194,
      "grad_norm": 2.6476786136627197,
      "learning_rate": 6.795139524665672e-06,
      "loss": 0.6539,
      "step": 5600
    },
    {
      "epoch": 0.9054086252084822,
      "grad_norm": 1.9348840713500977,
      "learning_rate": 6.665080739164576e-06,
      "loss": 0.6442,
      "step": 5700
    },
    {
      "epoch": 0.9212929870542451,
      "grad_norm": 2.0530927181243896,
      "learning_rate": 6.533742069272302e-06,
      "loss": 0.6528,
      "step": 5800
    },
    {
      "epoch": 0.9371773489000079,
      "grad_norm": 2.226409912109375,
      "learning_rate": 6.401224470041424e-06,
      "loss": 0.6352,
      "step": 5900
    },
    {
      "epoch": 0.9530617107457708,
      "grad_norm": 2.247610092163086,
      "learning_rate": 6.26762980272276e-06,
      "loss": 0.6369,
      "step": 6000
    },
    {
      "epoch": 0.9689460725915336,
      "grad_norm": 1.9023547172546387,
      "learning_rate": 6.133060756468509e-06,
      "loss": 0.6488,
      "step": 6100
    },
    {
      "epoch": 0.9848304344372965,
      "grad_norm": 3.473444938659668,
      "learning_rate": 5.997620769398991e-06,
      "loss": 0.6429,
      "step": 6200
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.6273961067199707,
      "eval_runtime": 588.0625,
      "eval_samples_per_second": 18.889,
      "eval_steps_per_second": 2.362,
      "step": 6296
    }
  ],
  "logging_steps": 100,
  "max_steps": 12590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.8530340830498e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
